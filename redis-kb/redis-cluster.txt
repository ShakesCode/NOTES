===========================
REDIS CLUSTER 
===========================
https://redis.io/topics/cluster-tutorial  --> on same machine

cheat sheet - https://willwarren.com/2017/10/redis-cluster-cheatsheet/

https://stackoverflow.com/questions/37655523/redis-cluster-different-machines --> on different machines 
--> with redis_trib.rb

https://www.linode.com/docs/applications/big-data/how-to-install-and-configure-a-redis-cluster-on-ubuntu-1604 --> multi mach
--> with redis_trib.rb
--> with sharding

https://www.digitalocean.com/community/tutorials/how-to-configure-a-redis-cluster-on-ubuntu-14-04 --> differenent machines 
--> more detailed 
--> with slaveof directive

https://developers.redhat.com/blog/2017/06/09/how-to-setup-a-redis-server-cluster-on-red-hat/ --> diff mach, with script

https://redislabs.com/redis-enterprise-documentation/administering/cluster-operations/new-cluster-setup/


- INSTALL RUBY
Needed for redis-trib.rb
# apt-get install ruby

- INSTALL REDIS GEM
# gem install redis

====================================
MULTI-MASTER CLUSTER
====================================
# create cluster with three masters
./redis-trib.rb create 110.163.70.47:6379 110.163.71.39:6379 110.163.71.91:6379

# add one slave each
Syntax:
./redis-trib.rb add-node --slave --master-id <id of the master> <slave ip>:<slave port> <master ip>:<master port>

./redis-trib.rb add-node --slave --master-id 84ff05dd70877ac1dc693bcb97a8b62f59c918ca 110.163.71.39:6380 110.163.70.47:6379
./redis-trib.rb add-node --slave --master-id ddbeecc18ff64f4e4b5376718a2b00564f3e4c04 110.163.71.91:6380 110.163.71.39:6379
./redis-trib.rb add-node --slave --master-id bb98cc4aa5631764f608c8b086285e22a19485a7 110.163.70.47:6380 110.163.71.91:6379

Alternate syntax:
./redis-trib.rb add-node --slave <slave ip>:<slave port> <any random master ip>:<its port>
Note that the command line here is exactly like the one we used to add a new master, 
so we are not specifying to which master we want to add the replica. In this case what happens is that 
redis-trib will add the new node as replica of a random master among the masters with less replicas.

=======
OUTPUTS
=======

- CREATE CLUSTER
root@redisc1:/home/redis/redis-4.0.2/src# ./redis-trib.rb create 110.163.70.47:6379 110.163.71.39:6379 110.163.71.91:6379
>>> Creating cluster
>>> Performing hash slots allocation on 3 nodes...
Using 3 masters:
110.163.70.47:6379
110.163.71.39:6379
110.163.71.91:6379
M: 84ff05dd70877ac1dc693bcb97a8b62f59c918ca 110.163.70.47:6379
   slots:0-5460 (5461 slots) master
M: ddbeecc18ff64f4e4b5376718a2b00564f3e4c04 110.163.71.39:6379
   slots:5461-10922 (5462 slots) master
M: bb98cc4aa5631764f608c8b086285e22a19485a7 110.163.71.91:6379
   slots:10923-16383 (5461 slots) master
Can I set the above configuration? (type 'yes' to accept): yes
>>> Nodes configuration updated
>>> Assign a different config epoch to each node
>>> Sending CLUSTER MEET messages to join the cluster
Waiting for the cluster to join..
>>> Performing Cluster Check (using node 110.163.70.47:6379)
M: 84ff05dd70877ac1dc693bcb97a8b62f59c918ca 110.163.70.47:6379
   slots:0-5460 (5461 slots) master
   0 additional replica(s)
M: bb98cc4aa5631764f608c8b086285e22a19485a7 110.163.71.91:6379
   slots:10923-16383 (5461 slots) master
   0 additional replica(s)
M: ddbeecc18ff64f4e4b5376718a2b00564f3e4c04 110.163.71.39:6379
   slots:5461-10922 (5462 slots) master
   0 additional replica(s)
[OK] All nodes agree about slots configuration.
>>> Check for open slots...
>>> Check slots coverage...
[OK] All 16384 slots covered.

- VERIFY CLUSTER - BEFORE ADDING SLAVES
# redis-cli -c -h 110.163.71.91 -p 6379
110.163.71.91:6379> cluster nodes
ddbeecc18ff64f4e4b5376718a2b00564f3e4c04 110.163.71.39:6379@16379 master - 0 1510574587580 2 connected 5461-10922
84ff05dd70877ac1dc693bcb97a8b62f59c918ca 110.163.70.47:6379@16379 master - 0 1510574586578 1 connected 0-5460
bb98cc4aa5631764f608c8b086285e22a19485a7 192.168.10.14:6379@16379 myself,master - 0 1510574586000 3 connected 10923-16383

- VERIFY CLUSTER - AFTER ADDING SLAVES
root@redisc1:/home/redis/redis-4.0.2/src# redis-cli -c -h 110.163.71.91 -p 6379
110.163.71.91:6379> cluster nodes
84ff05dd70877ac1dc693bcb97a8b62f59c918ca 110.163.70.47:6379@16379 master - 0 1510575166000 1 connected 0-5460
790d23dd6021f503ce2ef8a41f6670ba80bf1281 110.163.71.39:6380@16380 slave 84ff05dd70877ac1dc693bcb97a8b62f59c918ca 0 1510575166801 1 connected
1dd9ce2b695e9244d749fa068be5e6510e8c8d03 110.163.71.91:6380@16380 slave ddbeecc18ff64f4e4b5376718a2b00564f3e4c04 0 1510575166000 2 connected
f818f1c94855f9d37fe3505914bdec74eec3dcb5 110.163.70.47:6380@16380 slave bb98cc4aa5631764f608c8b086285e22a19485a7 0 1510575165798 3 connected
ddbeecc18ff64f4e4b5376718a2b00564f3e4c04 110.163.71.39:6379@16379 master - 0 1510575167803 2 connected 5461-10922
bb98cc4aa5631764f608c8b086285e22a19485a7 192.168.10.14:6379@16379 myself,master - 0 1510575165000 3 connected 10923-16383

- ADDING SLAVE
root@redisc1:/home/redis/redis-4.0.2/src# ./redis-trib.rb add-node --slave --master-id 84ff05dd70877ac1dc693bcb97a8b62f59c918ca 110.163.71.39:6380 110.163.70.47:6379
>>> Adding node 110.163.71.39:6380 to cluster 110.163.70.47:6379
>>> Performing Cluster Check (using node 110.163.70.47:6379)
M: 84ff05dd70877ac1dc693bcb97a8b62f59c918ca 110.163.70.47:6379
   slots:0-5460 (5461 slots) master
   0 additional replica(s)
M: bb98cc4aa5631764f608c8b086285e22a19485a7 110.163.71.91:6379
   slots:10923-16383 (5461 slots) master
   0 additional replica(s)
M: ddbeecc18ff64f4e4b5376718a2b00564f3e4c04 110.163.71.39:6379
   slots:5461-10922 (5462 slots) master
   0 additional replica(s)
[OK] All nodes agree about slots configuration.
>>> Check for open slots...
>>> Check slots coverage...
[OK] All 16384 slots covered.
>>> Send CLUSTER MEET to node 110.163.71.39:6380 to make it join the cluster.
Waiting for the cluster to join.
>>> Configure node as replica of 110.163.70.47:6379.
[OK] New node added correctly.

root@redisc1:/home/redis/redis-4.0.2/src# ./redis-trib.rb add-node --slave --master-id ddbeecc18ff64f4e4b5376718a2b00564f3e4c04 110.163.71.91:6380 110.163.71.39:6379
>>> Adding node 110.163.71.91:6380 to cluster 110.163.71.39:6379
>>> Performing Cluster Check (using node 110.163.71.39:6379)
M: ddbeecc18ff64f4e4b5376718a2b00564f3e4c04 110.163.71.39:6379
   slots:5461-10922 (5462 slots) master
   0 additional replica(s)
M: bb98cc4aa5631764f608c8b086285e22a19485a7 110.163.71.91:6379
   slots:10923-16383 (5461 slots) master
   0 additional replica(s)
S: 790d23dd6021f503ce2ef8a41f6670ba80bf1281 110.163.71.39:6380
   slots: (0 slots) slave
   replicates 84ff05dd70877ac1dc693bcb97a8b62f59c918ca
M: 84ff05dd70877ac1dc693bcb97a8b62f59c918ca 110.163.70.47:6379
   slots:0-5460 (5461 slots) master
   1 additional replica(s)
[OK] All nodes agree about slots configuration.
>>> Check for open slots...
>>> Check slots coverage...
[OK] All 16384 slots covered.
>>> Send CLUSTER MEET to node 110.163.71.91:6380 to make it join the cluster.
Waiting for the cluster to join.
>>> Configure node as replica of 110.163.71.39:6379.
[OK] New node added correctly.


root@redisc1:/home/redis/redis-4.0.2/src# ./redis-trib.rb add-node --slave --master-id bb98cc4aa5631764f608c8b086285e22a19485a7 110.163.70.47:6380 110.163.71.91:6379
>>> Adding node 110.163.70.47:6380 to cluster 110.163.71.91:6379
>>> Performing Cluster Check (using node 110.163.71.91:6379)
M: bb98cc4aa5631764f608c8b086285e22a19485a7 110.163.71.91:6379
   slots:10923-16383 (5461 slots) master
   0 additional replica(s)
M: 84ff05dd70877ac1dc693bcb97a8b62f59c918ca 110.163.70.47:6379
   slots:0-5460 (5461 slots) master
   1 additional replica(s)
S: 790d23dd6021f503ce2ef8a41f6670ba80bf1281 110.163.71.39:6380
   slots: (0 slots) slave
   replicates 84ff05dd70877ac1dc693bcb97a8b62f59c918ca
S: 1dd9ce2b695e9244d749fa068be5e6510e8c8d03 110.163.71.91:6380
   slots: (0 slots) slave
   replicates ddbeecc18ff64f4e4b5376718a2b00564f3e4c04
M: ddbeecc18ff64f4e4b5376718a2b00564f3e4c04 110.163.71.39:6379
   slots:5461-10922 (5462 slots) master
   1 additional replica(s)
[OK] All nodes agree about slots configuration.
>>> Check for open slots...
>>> Check slots coverage...
[OK] All 16384 slots covered.
>>> Send CLUSTER MEET to node 110.163.70.47:6380 to make it join the cluster.
Waiting for the cluster to join.
>>> Configure node as replica of 110.163.71.91:6379.
[OK] New node added correctly.
root@redisc1:/home/redis/redis-4.0.2/src# 

----------------------------------
REMOVING MASTER NODES FROM CLUSTER - WITH NO SLAVES UNDER THEM
----------------------------------
# ./redis-trib.rb del-node 10.63.70.47:6380 0d9356adc1fd9291e312d7ee529255074cbda133
>>> Removing node 0d9356adc1fd9291e312d7ee529255074cbda133 from cluster 10.63.70.47:6380
[ERR] Node 10.63.70.47:6380 is not empty! Reshard data away and try again.

# ./redis-trib.rb rebalance --weight 0d9356adc1fd9291e312d7ee529255074cbda133=0 10.63.70.47:6380
>>> Performing Cluster Check (using node 110.63.170.147:6380)
[OK] All nodes agree about slots configuration.
>>> Check for open slots...
>>> Check slots coverage...
[OK] All 16384 slots covered.
>>> Rebalancing across 3 nodes. Total weight = 2.0
Moving 2731 slots from 110.63.170.147:6380 to 110.63.171.191:6380
#############################################################
#############################################################
#############################################################

# ./redis-trib.rb del-node 110.63.170.147:6380 0d9356adc1fd9291e312d7ee529255074cbda133
>>> Removing node 0d9356adc1fd9291e312d7ee529255074cbda133 from cluster 10.63.70.47:6380
>>> Sending CLUSTER FORGET messages to the cluster...
>>> SHUTDOWN the node.

- SIMILARLY, REBALANCE THE OTHER NODE AND DROP IT

- THE LAST NODE CAN BE A PROBLEM
It wont drop when running
It wont drop when stopped
# ./redis-trib.rb del-node 110.63.171.191:6380 1c3d30f6de183480fdfe1266d8a5adaccd04d8df
>>> Removing node 1c3d30f6de183480fdfe1266d8a5adaccd04d8df from cluster 110.63.171.191:6380
[ERR] Sorry, can't connect to node 110.63.171.191:6380

