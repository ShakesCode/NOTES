CONTAINERS
Containers share host’s kernel
VM’s have their own kernels

CGroups, Namespaces
- resource limit capabilities for processes??
- https://www.netdevconf.org/1.1/tutorial-namespaces-and-cgroups-basis-linux-containers-rami-rosen.html

cgroups (abbreviated from control groups) is a Linux kernel feature that limits, accounts for, and isolates the resource usage (CPU, memory, disk I/O, network, etc.) of a collection of processes.

Linux containers - LXC
Docker - an abstraction to use cgroups and namespaces better

VMs - set CPU and memory for each
Container - 

KUBERNETES
Written in ‘go’, open source
misos - apache
nomad - hashi
white paper

Master node
Worker node

Master node consists of API servers, controller manager, scheduler
Everything that hits Kube hits api server
API can do what kubectl does

Scheduler - checks where capacity is in various nodes and runs the load there
Controller manager - controller to manage stuff based on annotations and labels in the yaml file
- checks current state and desired state (like need 3 but one is down …)

Etcd - key-value store
- maintain cluster state
- keeps itself HA talking to peers

We can create our own controller and deploy to controller manager
- Prometheus is one such controller - reads all containers annotations and pulls that data
- Kube does not have cron - so some people have written pods that wake up periodically and do jobs

PODS - 
A pod can have multiple container in it

SERVICES -
Load balancer for pods
A service can be created for sets of pods

CONFIG MAP-
If some dependencies are there outside of a pod - define it here
A pod can contact that resource and go back to the pod

SECRETS-
Encrypted items for use of pods/containers

Both configmap and secret can be available in a POD, or keep secrets in a different location

NAMESPACES-
For security and resource limits
- no question of segmenting persistent data as Kube does not support persistence
Logical division in the cluster - as namespaces
App teams can deploy their pods in different namespaces
Tokens are issued to apps in specific namespaces - no pem/crt as of now
There is no concept of ‘users’ in Kube
* Read-only tokens are also possible for namespaces
Namespace can span across nodes


GKE-
Google Kuberetes Engine
Managed service by google
We can create Kube cluster and get a token to access it
No namespaces in GKE

Custom cluster with own nodes we can create namespaces

QUOTA-
Namespace and Pod level quotas - yml file
- Limits (like upper limit)
- Requests (like min/lower limit)
Limits
- at pod or namespace level - limits.cpu/mem
Requests
- min resources absolutely needed for the pod to run
- always assured

GCR - 
GKE -
Gcloud -

KUBECONTEXT-
Multiple clusters
Cluster admin connects to each cluster and manage something
When kubectl is installed, in the root folder .kube is created and one of the files in it is a config file
The config file has info to connect to cluster
- token and api server info for each cluster
- this is the context for a cluster
Switch the context and kubectl connects to that cluster (kubeconfig use context)
kubectl has commands to set context info in the config files


WORKER NODES-
Kubelet
Kube Proxy

Scheduler contacts kubelet that is in every node
Kubelet listens to scheduler and serves - like creating a container

Kube has internal DNS
servicename.namespace.svc

OVERCOMMIT-
Not sure if it can be done… maybe yes

LABELS, NODECONNECTORS
- Namepspace to tie to specific nodes

TAINTING
- nodes to serve only specific pods or pods of specific namespaces
https://medium.com/@alejandro.ramirez.ch/reserving-a-kubernetes-node-for-specific-nodes-e75dc8297076

===========================
HANDS ON
===========================

-rwx------  1 dbgsm0  DHC\Domain Users  70232912 Jul  6 10:16 kubectl
-rwx------  1 dbgsm0  DHC\Domain Users  82125092 Jul  6 10:34 minikube
$ minikube start
Starting local Kubernetes v1.6.4 cluster...
Starting VM...
Downloading Minikube ISO
 90.95 MB / 90.95 MB [==============================================] 100.00% 0s







